{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Loan Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIPTION\n",
    "\n",
    "For safe and secure lending experience, it's important to analyze the past data. In this project, you have to build a deep learning model to predict the chance of default for future loans using the historical data. As you will see, this dataset is highly imbalanced and includes a lot of features that make this problem more challenging.\n",
    "\n",
    "Objective: Create a model that predicts whether or not an applicant will be able to repay a loan using historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'adam' from 'keras.optimizers' (C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m      \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m      \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m  \u001b[38;5;28;01mimport\u001b[39;00m adam\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'adam' from 'keras.optimizers' (C:\\Users\\Premalatha\\anaconda3\\Lib\\site-packages\\keras\\optimizers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing    import LabelEncoder\n",
    "from sklearn.impute           import SimpleImputer\n",
    "from sklearn.preprocessing    import StandardScaler\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.metrics          import accuracy_score \n",
    "from imblearn.over_sampling   import SMOTE\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib \n",
    "%matplotlib inline \n",
    "\n",
    "# ANN Modules\n",
    "import keras\n",
    "from keras.models      import Sequential\n",
    "from keras.layers      import Dense, Dropout\n",
    "from keras.optimizers  import adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"loan_data.csv/loan_data.csv\")\n",
    "df= df.drop(['SK_ID_CURR'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['EMERGENCYSTATE_MODE'])]\n",
    "#EMERGENCYSTATE_MODE--> this column contains around 145755 of missing values in it  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['CODE_GENDER'] != 'XNA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the missing value in lable column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NAME_TYPE_SUITE'] = df['NAME_TYPE_SUITE'].replace(np.nan,'Other_C')\n",
    "df['NAME_FAMILY_STATUS'] = df['NAME_FAMILY_STATUS'].replace('Unknown', 'Married')\n",
    "df['OCCUPATION_TYPE'] = df['OCCUPATION_TYPE'].replace(np.nan,'Others')\n",
    "df['WALLSMATERIAL_MODE'] = df['WALLSMATERIAL_MODE'].replace(np.nan,'Others')\n",
    "df['HOUSETYPE_MODE'] = df['HOUSETYPE_MODE'].replace(np.nan,'Unkown')\n",
    "df['FONDKAPREMONT_MODE'] = df['FONDKAPREMONT_MODE'].replace(np.nan,'not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['AMT_REQ_CREDIT_BUREAU_YEAR'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.describe(include=['object']).columns.values\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for lab in labels:\n",
    "    le.fit(df[lab].values)\n",
    "    df[lab] = le.transform(df[lab])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_column = df.columns[df.isnull().any()]\n",
    "print('Percentage of nan values :       %')\n",
    "print()\n",
    "print(df[null_column].isnull().sum()/df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['EXT_SOURCE_1','OWN_CAR_AGE','COMMONAREA_AVG','FLOORSMIN_AVG','LIVINGAPARTMENTS_AVG','COMMONAREA_MODE','NONLIVINGAPARTMENTS_AVG','FLOORSMIN_MODE','LIVINGAPARTMENTS_MODE','NONLIVINGAPARTMENTS_MODE','COMMONAREA_MEDI','FLOORSMIN_MEDI','LIVINGAPARTMENTS_MEDI','NONLIVINGAPARTMENTS_MEDI'], axis=1)\n",
    "\n",
    "#since these columns contains more tham 39% of nan values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['AMT_ANNUITY'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp1 = SimpleImputer(missing_values= np.nan, strategy='mean')\n",
    "imp2 = SimpleImputer(missing_values= np.nan, strategy='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['AMT_GOODS_PRICE','EXT_SOURCE_2',\n",
    "    'EXT_SOURCE_3','APARTMENTS_AVG',\n",
    "    'BASEMENTAREA_AVG','YEARS_BEGINEXPLUATATION_AVG',\n",
    "    'YEARS_BUILD_AVG','ELEVATORS_AVG',\n",
    "    'ENTRANCES_AVG','FLOORSMAX_AVG',\n",
    "    'LANDAREA_AVG','LIVINGAREA_AVG',\n",
    "    'NONLIVINGAREA_AVG','APARTMENTS_MODE',\n",
    "    'BASEMENTAREA_MODE','YEARS_BEGINEXPLUATATION_MODE',\n",
    "    'YEARS_BUILD_MODE','ELEVATORS_MODE','ENTRANCES_MODE',\n",
    "    'FLOORSMAX_MODE','LANDAREA_MODE','LIVINGAREA_MODE',\n",
    "    'NONLIVINGAREA_MODE','APARTMENTS_MEDI',\n",
    "    'BASEMENTAREA_MEDI','BASEMENTAREA_MEDI',\n",
    "    'YEARS_BEGINEXPLUATATION_MEDI','YEARS_BUILD_MEDI',\n",
    "    'ELEVATORS_MEDI','ENTRANCES_MEDI','FLOORSMAX_MEDI',\n",
    "    'LANDAREA_MEDI','LIVINGAREA_MEDI',\n",
    "    'NONLIVINGAREA_MEDI','TOTALAREA_MODE',]]             = imp1.fit_transform(df[['AMT_GOODS_PRICE','EXT_SOURCE_2',\n",
    "                                                                                  'EXT_SOURCE_3','APARTMENTS_AVG',\n",
    "                                                                                  'BASEMENTAREA_AVG','YEARS_BEGINEXPLUATATION_AVG',\n",
    "                                                                                  'YEARS_BUILD_AVG','ELEVATORS_AVG',\n",
    "                                                                                  'ENTRANCES_AVG','FLOORSMAX_AVG',\n",
    "                                                                                  'LANDAREA_AVG','LIVINGAREA_AVG',\n",
    "                                                                                  'NONLIVINGAREA_AVG','APARTMENTS_MODE',\n",
    "                                                                                  'BASEMENTAREA_MODE','YEARS_BEGINEXPLUATATION_MODE',\n",
    "                                                                                  'YEARS_BUILD_MODE','ELEVATORS_MODE','ENTRANCES_MODE',\n",
    "                                                                                  'FLOORSMAX_MODE','LANDAREA_MODE','LIVINGAREA_MODE',\n",
    "                                                                                  'NONLIVINGAREA_MODE','APARTMENTS_MEDI',\n",
    "                                                                                  'BASEMENTAREA_MEDI','BASEMENTAREA_MEDI',\n",
    "                                                                                  'YEARS_BEGINEXPLUATATION_MEDI','YEARS_BUILD_MEDI',\n",
    "                                                                                  'ELEVATORS_MEDI','ENTRANCES_MEDI','FLOORSMAX_MEDI',\n",
    "                                                                                  'LANDAREA_MEDI','LIVINGAREA_MEDI',\n",
    "                                                                                  'NONLIVINGAREA_MEDI','TOTALAREA_MODE',]]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['CNT_FAM_MEMBERS','OBS_30_CNT_SOCIAL_CIRCLE',\n",
    "    'DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "    'OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE',]] = imp2.fit_transform(df[['CNT_FAM_MEMBERS','OBS_30_CNT_SOCIAL_CIRCLE',\n",
    "                                                                                      'DEF_30_CNT_SOCIAL_CIRCLE','OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "                                                                                      'OBS_60_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE',]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns=df.columns[df.isnull().any()]\n",
    "print('Percentage of nan values :       %')\n",
    "print()\n",
    "print(df[null_columns].isnull().sum()/df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding column with zero variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df.var()[df.var()==0].index.values\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['FLAG_DOCUMENT_2','FLAG_MOBIL'],axis=1)\n",
    "\n",
    "#since this column contains only one categorical variable, ie zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df.TARGET.value_counts()\n",
    "\n",
    "print('Counts of Class 0 :',class_counts[0])\n",
    "print('Counts of Class 1 :',class_counts[1])\n",
    "print()\n",
    "print('Propotion ---> ',round(class_counts[0]/len(df.TARGET)*100),':',round(class_counts[1]/len(df.TARGET)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "df[['AMT_INCOME_TOTAL','AMT_ANNUITY',\n",
    "   'AMT_CREDIT','AMT_GOODS_PRICE',\n",
    "   'DAYS_BIRTH','DAYS_EMPLOYED',\n",
    "   'DAYS_REGISTRATION','DAYS_ID_PUBLISH',\n",
    "   'DAYS_LAST_PHONE_CHANGE']]              = sc.fit_transform(df[['AMT_INCOME_TOTAL','AMT_ANNUITY',\n",
    "                                                                  'AMT_CREDIT','AMT_GOODS_PRICE',\n",
    "                                                                  'DAYS_BIRTH','DAYS_EMPLOYED',\n",
    "                                                                  'DAYS_REGISTRATION','DAYS_ID_PUBLISH',\n",
    "                                                                  'DAYS_LAST_PHONE_CHANGE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the highly correlated columns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(corr, annot=False, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(np.bool))\n",
    "to_drop = [col for col in upper.columns if any(upper[col]>0.90)]\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=False, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data in Hold out method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('TARGET',axis=1)\n",
    "y = df.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size= 0.2, random_state= 10, stratify=y)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print()\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling the minimum class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTE(random_state= 10, n_jobs=-1,sampling_strategy='all' )\n",
    "\n",
    "\n",
    "#sampling_strategy='minority' ----> resample only the minority class;\n",
    "#sampling_strategy='not minority' ----> resample all classes but the minority class;\n",
    "#sampling_strategy='not majority' ----> resample all classes but the majority class;\n",
    "#sampling_strategy='all' ----> resample all classes;\n",
    "#sampling_strategy='auto' ----> equivalent to 'not majority'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = smt.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units= 53,activation = 'relu',input_dim=79)) # first hidden and first input layer\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units= 53,activation = 'relu')) # second hidden layer\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units= 1,activation = 'sigmoid')) # output layer \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,batch_size=10,epochs=20,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss : ', score[0])\n",
    "print('Test accuracy : ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test) #predcting the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the model is : ',round(accuracy_score(y_pred.round(), y_test)*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
